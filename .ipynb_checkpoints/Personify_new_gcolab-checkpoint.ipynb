{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LaapwWNuJ4F"
   },
   "source": [
    "PERSONIFY \n",
    "- Data Science and Analytics Project  \n",
    "- MBTI Personality Detection from Persons' Text messages or social posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TssaP-G7uJ4G",
    "outputId": "e0030644-a55a-4f5b-c9a3-fe765aaaf5a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import All Necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "wn = nltk.stem.WordNetLemmatizer()\n",
    "pstemmer = nltk.stem.PorterStemmer()\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# nltk.download() # to choose any pkj to download\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "import multiprocessing\n",
    "import time\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uBkIvopOuJ4L",
    "outputId": "0ce89aa2-025e-4cfa-8294-015cf3d6b11c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQlBePUUuJ4K"
   },
   "source": [
    "## Data\n",
    "    -Two columns- \n",
    "        -Personality type \n",
    "        -Posts text - that portrays the personality\n",
    "    -Contains at least 50 diferrent post texts separated with |||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "id": "AZSc88o8GuHv",
    "outputId": "cd796677-b8f1-4d18-f3ab-b0442ac7cd17"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'18/37 @.@|||Science  is not perfect. No scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'No, I can't draw on my own nails (haha). Thos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'I tend to build up a collection of things on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>I'm not sure, that's a good question. The dist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=w8-egj0y8Qs||...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce...\n",
       "5  INTJ  '18/37 @.@|||Science  is not perfect. No scien...\n",
       "6  INFJ  'No, I can't draw on my own nails (haha). Thos...\n",
       "7  INTJ  'I tend to build up a collection of things on ...\n",
       "8  INFJ  I'm not sure, that's a good question. The dist...\n",
       "9  INTP  'https://www.youtube.com/watch?v=w8-egj0y8Qs||..."
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read databasea\n",
    "odata = pd.read_csv(\"/content/drive/My Drive/Data_Science/data_sets/mbti.csv\")\n",
    "odata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s2auA83WuJ4O",
    "outputId": "f0d47e40-a175-4754-9fe1-097e8078d603"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       INFJ\n",
       "1       ENTP\n",
       "2       INTP\n",
       "3       INTJ\n",
       "4       ENTJ\n",
       "        ... \n",
       "8670    ISFP\n",
       "8671    ENFP\n",
       "8672    INTP\n",
       "8673    INFP\n",
       "8674    INFP\n",
       "Name: type, Length: 8675, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input text to detect personality type \n",
    "X = odata[\"posts\"]\n",
    "# # Output Class values 16 personality types or classes\n",
    "Y = odata[\"type\"]\n",
    "Y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-8ArCL2uJ4Q"
   },
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZGmFBV1JuJ4R"
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "odata.isnull().sum()\n",
    "# if missing values found either remove row or coloumn or replace with mean, median or mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "okrJ5E97uJ4T"
   },
   "outputs": [],
   "source": [
    "odata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "l_iHmgJ-uJ4V",
    "outputId": "2713c537-4b2a-4172-9077-d1c8a314a36f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'MBTI-Types Frequency')"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Showing a bar chart of MBTI Personality types and their occurences in the data set\n",
    "mbti_types= Y.drop_duplicates()\n",
    "mbti_occurances = Y.value_counts()\n",
    "y_pos = np.arange(len(mbti_types)) \n",
    "\n",
    "plt.figure(figsize=(25,10))\n",
    "plt.bar(y_pos, mbti_occurances, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, mbti_types)\n",
    "plt.ylabel('MBTI-Frequency')\n",
    "plt.title('MBTI-Types Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "dvi4tICyuJ4e",
    "outputId": "4a2490ca-805e-4069-c553-5f20f3a507c9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if GPU is available \n",
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRzp5D5ZuJ4Y"
   },
   "source": [
    "## Selective Word Removal \n",
    "    -(removing links, unecessary stoping words like a, the or, and..., or  MBTI types if may be given in text and stemize)\n",
    "     \n",
    "    -Remove Links\n",
    "    -Tokenize Sentences and words\n",
    "    -Remove Stop words\n",
    "    -Lemmatize (Stemize) words\n",
    "    -Padding (words to ints of same length) - (Only Needed for Deep Learning Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4NAoNlhJGjzf",
    "outputId": "3a4b6fe0-9792-4682-82a2-a92e56217568"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (0.48.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba) (50.3.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from numba) (1.18.5)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba) (0.31.0)\n",
      "Collecting contractions\n",
      "  Downloading https://files.pythonhosted.org/packages/00/92/a05b76a692ac08d470ae5c23873cf1c9a041532f1ee065e74b374f218306/contractions-0.0.25-py2.py3-none-any.whl\n",
      "Collecting textsearch\n",
      "  Downloading https://files.pythonhosted.org/packages/42/a8/03407021f9555043de5492a2bd7a35c56cc03c2510092b5ec018cae1bbf1/textsearch-0.0.17-py2.py3-none-any.whl\n",
      "Collecting Unidecode\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
      "\u001b[K     |████████████████████████████████| 245kB 15.3MB/s \n",
      "\u001b[?25hCollecting pyahocorasick\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz (312kB)\n",
      "\u001b[K     |████████████████████████████████| 317kB 32.7MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
      "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.0-cp36-cp36m-linux_x86_64.whl size=81698 sha256=ef88879d5fe3d2f5a11ab23b8a81f8d1d4ff511bb3aad0684c243345dc93a095\n",
      "  Stored in directory: /root/.cache/pip/wheels/0a/90/61/87a55f5b459792fbb2b7ba6b31721b06ff5cf6bde541b40994\n",
      "Successfully built pyahocorasick\n",
      "Installing collected packages: Unidecode, pyahocorasick, textsearch, contractions\n",
      "Successfully installed Unidecode-1.1.1 contractions-0.0.25 pyahocorasick-1.4.0 textsearch-0.0.17\n",
      "Collecting fsspec>=0.3.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/8b/1df260f860f17cb08698170153ef7db672c497c1840dcc8613ce26a8a005/fsspec-0.8.4-py3-none-any.whl (91kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 7.3MB/s \n",
      "\u001b[?25hInstalling collected packages: fsspec\n",
      "Successfully installed fsspec-0.8.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/722 [00:00<?, ?it/s]/content/drive/My Drive/Data_Science/preprocess.py:132: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"preprocess_text\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at /content/drive/My Drive/Data_Science/preprocess.py (134)\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 134:\n",
      "  def preprocess_text(self, text):\n",
      "    self.text = text\n",
      "    ^\n",
      "\n",
      "  @jit(parallel=True)\n",
      "/content/drive/My Drive/Data_Science/preprocess.py:132: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"preprocess_text\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at /content/drive/My Drive/Data_Science/preprocess.py (134)\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 134:\n",
      "  def preprocess_text(self, text):\n",
      "    self.text = text\n",
      "    ^\n",
      "\n",
      "  @jit(parallel=True)\n",
      "/content/drive/My Drive/Data_Science/preprocess.py:132: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"preprocess_text\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at /content/drive/My Drive/Data_Science/preprocess.py (134)\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 134:\n",
      "  def preprocess_text(self, text):\n",
      "    self.text = text\n",
      "    ^\n",
      "\n",
      "  @jit(parallel=True)\n",
      "/content/drive/My Drive/Data_Science/preprocess.py:132: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"preprocess_text\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at /content/drive/My Drive/Data_Science/preprocess.py (134)\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 134:\n",
      "  def preprocess_text(self, text):\n",
      "    self.text = text\n",
      "    ^\n",
      "\n",
      "  @jit(parallel=True)\n",
      "/content/drive/My Drive/Data_Science/preprocess.py:132: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"preprocess_text\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at /content/drive/My Drive/Data_Science/preprocess.py (134)\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 134:\n",
      "  def preprocess_text(self, text):\n",
      "    self.text = text\n",
      "    ^\n",
      "\n",
      "  @jit(parallel=True)\n",
      "/content/drive/My Drive/Data_Science/preprocess.py:132: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"preprocess_text\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at /content/drive/My Drive/Data_Science/preprocess.py (134)\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 134:\n",
      "  def preprocess_text(self, text):\n",
      "    self.text = text\n",
      "    ^\n",
      "\n",
      "  @jit(parallel=True)\n",
      "/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"preprocess_text\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 133:\n",
      "  @jit(parallel=True)\n",
      "  def preprocess_text(self, text):\n",
      "  ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"preprocess_text\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 133:\n",
      "  @jit(parallel=True)\n",
      "  def preprocess_text(self, text):\n",
      "  ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 133:\n",
      "  @jit(parallel=True)\n",
      "  def preprocess_text(self, text):\n",
      "  ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 133:\n",
      "  @jit(parallel=True)\n",
      "  def preprocess_text(self, text):\n",
      "  ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"preprocess_text\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 133:\n",
      "  @jit(parallel=True)\n",
      "  def preprocess_text(self, text):\n",
      "  ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 133:\n",
      "  @jit(parallel=True)\n",
      "  def preprocess_text(self, text):\n",
      "  ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/content/drive/My Drive/Data_Science/preprocess.py:132: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"preprocess_text\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at /content/drive/My Drive/Data_Science/preprocess.py (134)\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 134:\n",
      "  def preprocess_text(self, text):\n",
      "    self.text = text\n",
      "    ^\n",
      "\n",
      "  @jit(parallel=True)\n",
      "/content/drive/My Drive/Data_Science/preprocess.py:132: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"preprocess_text\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at /content/drive/My Drive/Data_Science/preprocess.py (134)\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 134:\n",
      "  def preprocess_text(self, text):\n",
      "    self.text = text\n",
      "    ^\n",
      "\n",
      "  @jit(parallel=True)\n",
      "/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"preprocess_text\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 133:\n",
      "  @jit(parallel=True)\n",
      "  def preprocess_text(self, text):\n",
      "  ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 133:\n",
      "  @jit(parallel=True)\n",
      "  def preprocess_text(self, text):\n",
      "  ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"preprocess_text\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 133:\n",
      "  @jit(parallel=True)\n",
      "  def preprocess_text(self, text):\n",
      "  ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 133:\n",
      "  @jit(parallel=True)\n",
      "  def preprocess_text(self, text):\n",
      "  ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"preprocess_text\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 133:\n",
      "  @jit(parallel=True)\n",
      "  def preprocess_text(self, text):\n",
      "  ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 133:\n",
      "  @jit(parallel=True)\n",
      "  def preprocess_text(self, text):\n",
      "  ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/content/drive/My Drive/Data_Science/preprocess.py:132: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"preprocess_text\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at /content/drive/My Drive/Data_Science/preprocess.py (134)\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 134:\n",
      "  def preprocess_text(self, text):\n",
      "    self.text = text\n",
      "    ^\n",
      "\n",
      "  @jit(parallel=True)\n",
      "/content/drive/My Drive/Data_Science/preprocess.py:132: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"preprocess_text\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at /content/drive/My Drive/Data_Science/preprocess.py (134)\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 134:\n",
      "  def preprocess_text(self, text):\n",
      "    self.text = text\n",
      "    ^\n",
      "\n",
      "  @jit(parallel=True)\n",
      "/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"preprocess_text\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 133:\n",
      "  @jit(parallel=True)\n",
      "  def preprocess_text(self, text):\n",
      "  ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 133:\n",
      "  @jit(parallel=True)\n",
      "  def preprocess_text(self, text):\n",
      "  ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"preprocess_text\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 133:\n",
      "  @jit(parallel=True)\n",
      "  def preprocess_text(self, text):\n",
      "  ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 133:\n",
      "  @jit(parallel=True)\n",
      "  def preprocess_text(self, text):\n",
      "  ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/content/drive/My Drive/Data_Science/preprocess.py:132: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"preprocess_text\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at /content/drive/My Drive/Data_Science/preprocess.py (134)\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 134:\n",
      "  def preprocess_text(self, text):\n",
      "    self.text = text\n",
      "    ^\n",
      "\n",
      "  @jit(parallel=True)\n",
      "/content/drive/My Drive/Data_Science/preprocess.py:132: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"preprocess_text\" failed type inference due to: non-precise type pyobject\n",
      "[1] During: typing of argument at /content/drive/My Drive/Data_Science/preprocess.py (134)\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 134:\n",
      "  def preprocess_text(self, text):\n",
      "    self.text = text\n",
      "    ^\n",
      "\n",
      "  @jit(parallel=True)\n",
      "/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"preprocess_text\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 133:\n",
      "  @jit(parallel=True)\n",
      "  def preprocess_text(self, text):\n",
      "  ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 133:\n",
      "  @jit(parallel=True)\n",
      "  def preprocess_text(self, text):\n",
      "  ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"preprocess_text\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 133:\n",
      "  @jit(parallel=True)\n",
      "  def preprocess_text(self, text):\n",
      "  ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 133:\n",
      "  @jit(parallel=True)\n",
      "  def preprocess_text(self, text):\n",
      "  ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"preprocess_text\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 133:\n",
      "  @jit(parallel=True)\n",
      "  def preprocess_text(self, text):\n",
      "  ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"preprocess_text\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 133:\n",
      "  @jit(parallel=True)\n",
      "  def preprocess_text(self, text):\n",
      "  ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 133:\n",
      "  @jit(parallel=True)\n",
      "  def preprocess_text(self, text):\n",
      "  ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/usr/local/lib/python3.6/dist-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"drive/My Drive/Data_Science/preprocess.py\", line 133:\n",
      "  @jit(parallel=True)\n",
      "  def preprocess_text(self, text):\n",
      "  ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      " 14%|█▍        | 100/723 [00:39<04:04,  2.54it/s]\n",
      " 14%|█▍        | 100/723 [00:40<04:09,  2.50it/s]\n",
      " 14%|█▍        | 100/723 [00:39<04:06,  2.53it/s]\n",
      " 14%|█▍        | 100/723 [00:40<04:10,  2.49it/s]\n",
      " 14%|█▍        | 100/723 [00:40<04:10,  2.49it/s]\n",
      " 14%|█▍        | 100/723 [00:40<04:11,  2.48it/s]\n",
      " 14%|█▍        | 100/723 [00:40<04:11,  2.48it/s]\n",
      " 14%|█▍        | 100/723 [00:40<04:11,  2.47it/s]\n",
      " 14%|█▍        | 100/723 [00:40<04:11,  2.48it/s]\n",
      " 14%|█▍        | 100/722 [00:39<04:08,  2.51it/s]\n",
      " 14%|█▍        | 100/723 [00:40<04:09,  2.50it/s]\n",
      " 14%|█▍        | 100/723 [00:40<04:10,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 41.44967293739319 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       moment sportscent top ten play prank ha lifech...\n",
       "1       find lack post veri alarm sex bore posit often...\n",
       "2       good one _____ cours say know bless curs doe a...\n",
       "3       dear enjoy convers day esoter gab natur univer...\n",
       "4       fire anoth silli misconcept approach logic go ...\n",
       "                              ...                        \n",
       "8670    becaus alway think cat fi dom reason websit be...\n",
       "8671    thi thread alreadi exist someplac els doe heck...\n",
       "8672    mani question thing would take purpl pill pick...\n",
       "8673    veri conflict right come want children honestl...\n",
       "8674    ha long sinc personalitycaf although doe seem ...\n",
       "Name: posts, Length: 8675, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install numba\n",
    "# !pip install cudatoolkit\n",
    "# !pip install numba cudatoolkit pyculib\n",
    "# from numba import jit, cuda\n",
    "\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/')\n",
    "!pip install contractions\n",
    "from tqdm import tqdm\n",
    "from Data_Science.preprocess import CleanText\n",
    "ct = CleanText()\n",
    "\n",
    "# !pip install dask\n",
    "!pip install 'fsspec>=0.3.3'\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get\n",
    "import timeit\n",
    "# function optimized to run on gpu  \n",
    "\n",
    "# @jit\n",
    "# (target =\"cuda\")  \n",
    "def dask_this(df):\n",
    "  with tqdm(total=len(df)) as pbar:\n",
    "    res = df['posts'].apply(ct.preprocess_text)\n",
    "    pbar.update(100)\n",
    "  return res\n",
    "\n",
    "%timeit\n",
    "start_time = time.time()\n",
    "\n",
    "ddf = dd.from_pandas(data, npartitions=12)\n",
    "res = ddf.map_partitions(dask_this, meta=pd.Series([], dtype=str, name='posts')).compute(scheduler='processes', num_workers=12)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IlYHKRzvOiKA"
   },
   "outputs": [],
   "source": [
    "# Adding Y (type) values back with their relative posts for a df\n",
    "processed_data = pd.concat([Y, res], axis=1) # axis 1 = columnj\n",
    "\n",
    "#Exporting Preprocessed data to a new csv file\n",
    "processed_data.to_csv(\"/content/drive/My Drive/Data_Science/data_sets/mbti_processed_data_complete.csv\", index=False)\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JiA1znK49kf8"
   },
   "source": [
    "# Spliting dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1H_wb28hnaX8"
   },
   "source": [
    "## Train Test Split\n",
    "    Train test split approach\n",
    "    Training set 70%\n",
    "    Test set  30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "o2__Ywy0oTb1",
    "outputId": "e32e7db9-4312-4fe1-dfb9-244fc4435aa6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>and moment sportscent not top ten play prank w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>i am find the lack of me in these post veri al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good one _____ cours to which i say i know tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear i enjoy our convers the other day esoter ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>you are fire that is anoth silli misconcept th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>scienc is not perfect no scientist claim that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>no i can not draw on my own nail haha those we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>i tend to build up a collect of thing on my de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>i am not sure that is a good question the dist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>INTP</td>\n",
       "      <td>in thi posit where i have to actual let go of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  and moment sportscent not top ten play prank w...\n",
       "1  ENTP  i am find the lack of me in these post veri al...\n",
       "2  INTP  good one _____ cours to which i say i know tha...\n",
       "3  INTJ  dear i enjoy our convers the other day esoter ...\n",
       "4  ENTJ  you are fire that is anoth silli misconcept th...\n",
       "5  INTJ  scienc is not perfect no scientist claim that ...\n",
       "6  INFJ  no i can not draw on my own nail haha those we...\n",
       "7  INTJ  i tend to build up a collect of thing on my de...\n",
       "8  INFJ  i am not sure that is a good question the dist...\n",
       "9  INTP  in thi posit where i have to actual let go of ..."
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read partial processed data for comparing the evaluation metrics\n",
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv(\"/content/drive/My Drive/Data_Science/data_sets/mbti_processed_data5.csv\")\n",
    "Y = data[\"type\"]\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fLqGE3XVsef5",
    "outputId": "5309cd0d-dcb1-481e-f9fc-e8846333d50b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7263    INTJ\n",
       "8037    ENFP\n",
       "7864    INFJ\n",
       "6596    INFP\n",
       "5008    INTP\n",
       "        ... \n",
       "350     INFP\n",
       "79      INFP\n",
       "8039    INTP\n",
       "6936    ISTP\n",
       "5640    INFJ\n",
       "Name: type, Length: 6072, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Spliting data into Training and Test sets 80/20% or 70%/30%\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Use completely processed data \n",
    "# X = processed_data[\"posts\"]\n",
    "# Y = processed_data[\"type\"]\n",
    "\n",
    "# Using partial processed data\n",
    "X = data[\"posts\"]\n",
    "Y = data[\"type\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=100)\n",
    "X_train\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KmCvKtD5ti4e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgfQOYNhgcRv"
   },
   "source": [
    "# Preparing, Vectorizing data\n",
    "    Converting text data into vectors (numbers)\n",
    "    Computer understandable data for ML Model Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxnAiQ3fl-EC"
   },
   "source": [
    "## Vectorization \n",
    "    Extracting features(text-to-Nums) from text files\n",
    "In order to perform machine learning on text documents, we first need to turn the text content into numerical feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EsAH0HI5sVzc",
    "outputId": "8db9b8a1-6426-4e80-b952-aeca69d50c53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2603, 47179)"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vectorization of text posts into nums(vector counts)\n",
    "#CountVectorizer -builds a dictionary of features (key(word)->value{num|index}) and transforms documents to feature vectors:\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_train_counts.shape\n",
    "\n",
    "y_train_counts = count_vect.transform(y_train)\n",
    "y_train_counts.shape\n",
    "\n",
    "\n",
    "\n",
    "# converting test data set too will be needed.\n",
    "X_test_counts = count_vect.fit_transform(X_test)\n",
    "X_test_counts.shape\n",
    "\n",
    "y_test_counts = count_vect.transform(y_test)\n",
    "y_test_counts.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50XtW8eCsYSK"
   },
   "outputs": [],
   "source": [
    "# The index value of a word in the vocabulary is linked to its frequency in the whole training corpus.\n",
    "count_vect.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6eYUIwDxSMc"
   },
   "source": [
    "## Term Frequency (tf)\n",
    "    Dividing the number of occurrences of each word in a document by the total number of words in the document\n",
    "    #Term Frequency times \n",
    "    #Inverse Document Frequency” (tf-idf)\n",
    "    Downscaling weights for words that occur in many documents in the corpus and are therefore less informative than those that occur only in a smaller portion of the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gxq_DeHHuJ4r",
    "outputId": "a536c26e-70a2-4cf4-9cf9-3fbb953b1aa6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2603x47179 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2603 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TF-IDF Transformer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape\n",
    "\n",
    "y_train_tfidf = tfidf_transformer.transform(y_train_counts)\n",
    "y_train_tfidf.shape\n",
    "\n",
    "# test data \n",
    "X_test_tfidf = tfidf_transformer.fit_transform(X_test_counts)\n",
    "X_test_tfidf\n",
    "\n",
    "y_test_tfidf = tfidf_transformer.transform(y_test_counts)\n",
    "y_test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WF1RM9tI0106"
   },
   "outputs": [],
   "source": [
    "# #Pipeline -Combining (vectorizer => transformer => classifier) to work with data easily\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', MultinomialNB()),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WF8J5cnLmA5S"
   },
   "source": [
    "# Models Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kX04taDgsRlT"
   },
   "source": [
    "## Naive Bayes Multinomial Classification\n",
    "    Training Model-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2B6rDRILuJ4t",
    "outputId": "dd59e579-11df-4cc4-de6e-c72b57e3fe94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.18603134155273438 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#Training on 80% Train data\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "start_time = time.time()\n",
    "nb_clf = MultinomialNB()\n",
    "#text_clf needs training data into floats (nums)\n",
    "nb_clf.fit(X_train_tfidf, y_train)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6KvZwITbTg3A"
   },
   "outputs": [],
   "source": [
    "# Predection of Trainded Model-1 on 20% Test Data\n",
    "# Test data must be featured through the same chain of methods used for training data (countVector - Td-Idf)\n",
    "X_test_count = count_vect.transform(X_test)\n",
    "#Here only use tdidf-Transform() method instead of fitTransfer() - since they have already been fit to the training set (x_train)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_count)\n",
    "y_pred = nb_clf.predict(X_test_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwtAryX8Tiaf"
   },
   "source": [
    "Model 1 - Naive Bayes Evaluation matrix and score\n",
    "> Confusion Matrix & Accuracy\n",
    "\n",
    "\n",
    "> Precision & Recall\n",
    "\n",
    "\n",
    "> F1-Score & Support\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aIG9YLi9ZNXe",
    "outputId": "53848bb8-22e1-4ad8-b7b5-4fbe7f8371a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       1.00      0.00      0.00        53\n",
      "        ENFP       1.00      0.00      0.00       201\n",
      "        ENTJ       1.00      0.00      0.00        60\n",
      "        ENTP       1.00      0.00      0.00       206\n",
      "        ESFJ       1.00      0.00      0.00        17\n",
      "        ESFP       1.00      0.00      0.00        14\n",
      "        ESTJ       1.00      0.00      0.00        10\n",
      "        ESTP       1.00      0.00      0.00        25\n",
      "        INFJ       1.00      0.00      0.00       450\n",
      "        INFP       0.21      1.00      0.34       542\n",
      "        INTJ       1.00      0.00      0.00       355\n",
      "        INTP       1.00      0.00      0.00       397\n",
      "        ISFJ       1.00      0.00      0.00        53\n",
      "        ISFP       1.00      0.00      0.00        78\n",
      "        ISTJ       1.00      0.00      0.00        56\n",
      "        ISTP       1.00      0.00      0.00        86\n",
      "\n",
      "    accuracy                           0.21      2603\n",
      "   macro avg       0.95      0.06      0.02      2603\n",
      "weighted avg       0.84      0.21      0.07      2603\n",
      "\n",
      "Confusion Metrix: \n",
      " [[  0   0   0   0   0   0   0   0   0  53   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 201   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  60   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 206   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  17   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  25   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 450   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 542   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 355   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 397   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  53   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  78   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  56   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  86   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix and Accuracy Score of Naive Bayes\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_pred, zero_division=1))\n",
    "\n",
    "print(\"Confusion Metrix: \\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AhZPLHr0hmHZ",
    "outputId": "18998442-783b-4cc8-bb6b-ac9318b24c6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (0.17.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/content/drive/My Drive/Data_Science/personify_nb_model4.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the Naive Bayes machine learning model to a file\n",
    "!pip install joblib\n",
    "import joblib\n",
    "joblib.dump(nb_clf, \"/content/drive/My Drive/Data_Science/personify_nb_model4.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53eoUrb0MY6v"
   },
   "source": [
    "## Support Vector Machine (SVM) Classification Model\n",
    "    Training Model-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OvSkRzn8MX9I",
    "outputId": "45be033e-b2f9-4625-b3d1-684a27714cfb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovo', degree=3,\n",
       "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM -Feature Selection and Training\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "svm_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', svm.SVC(decision_function_shape='ovo')),])\n",
    "\n",
    "svm_clf.fit(X_train.values.astype(\"U\"), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zyzKhWxzO4UE"
   },
   "outputs": [],
   "source": [
    "#Predicting with SVM Model\n",
    "y_pred_svm = svm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfcBWoQ-QZSe"
   },
   "source": [
    "Model 2 - Support Vector Machine Evaluation matrix and score\n",
    "> Confusion Matrix & Accuracy\n",
    "\n",
    "> Precision & Recall\n",
    "\n",
    "> F1-Score & Support\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bBdpWraUQZSh",
    "outputId": "a5e8fddc-0f0a-4c47-f518-aedf4d1c2187"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       1.00      0.00      0.00        43\n",
      "        ENFP       0.53      0.06      0.10       139\n",
      "        ENTJ       1.00      0.00      0.00        35\n",
      "        ENTP       0.36      0.06      0.10       138\n",
      "        ESFJ       1.00      0.00      0.00        13\n",
      "        ESFP       1.00      0.00      0.00         8\n",
      "        ESTJ       1.00      0.00      0.00         8\n",
      "        ESTP       1.00      0.00      0.00        16\n",
      "        INFJ       0.34      0.37      0.35       295\n",
      "        INFP       0.35      0.76      0.48       356\n",
      "        INTJ       0.39      0.25      0.30       239\n",
      "        INTP       0.39      0.64      0.49       277\n",
      "        ISFJ       1.00      0.00      0.00        35\n",
      "        ISFP       1.00      0.00      0.00        47\n",
      "        ISTJ       1.00      0.00      0.00        24\n",
      "        ISTP       1.00      0.02      0.03        62\n",
      "\n",
      "    accuracy                           0.36      1735\n",
      "   macro avg       0.77      0.13      0.12      1735\n",
      "weighted avg       0.48      0.36      0.29      1735\n",
      "\n",
      "Confusion Metrix: \n",
      " [[  0   0   0   0   0   0   0   0  17  21   3   2   0   0   0   0]\n",
      " [  0   8   0   0   0   0   0   0  33  85   4   9   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   9   9   8   9   0   0   0   0]\n",
      " [  0   1   0   8   0   0   0   0  24  42  11  52   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   8   5   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   5   0   2   0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   3   1   3   0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0   2   7   1   5   0   0   0   0]\n",
      " [  0   1   0   2   0   0   0   0 110 143  17  22   0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0  38 269   8  40   0   0   0   0]\n",
      " [  0   0   0   5   0   0   0   0  37  57  59  81   0   0   0   0]\n",
      " [  0   0   0   4   0   0   0   0  20  61  16 176   0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0   9  20   1   4   0   0   0   0]\n",
      " [  0   1   0   1   0   0   0   0  10  28   2   5   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   6  10   7   0   0   0   0]\n",
      " [  0   0   0   2   0   0   0   0   9  10  10  30   0   0   0   1]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix and Accuracy Score of Naive Bayes\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_pred_svm, zero_division=1))\n",
    "\n",
    "print(\"Confusion Metrix: \\n\", confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k1a3E0eWQNQE",
    "outputId": "c6b4eb6d-806d-4cab-fc89-4aba5938c9a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (0.17.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/content/drive/My Drive/Data_Science/personify_svm_model.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the SVM machine learning model to a file\n",
    "!pip install joblib\n",
    "import joblib\n",
    "joblib.dump(svm_clf, \"/content/drive/My Drive/Data_Science/personify_svm_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfeEgSo4CsUy"
   },
   "source": [
    "## Passive Aggressive Classifier\n",
    "    Training Model-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ppihgKsBCqWV",
    "outputId": "a92f70cb-264a-4587-c3a2-20b0fc2c50a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=Non...\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 PassiveAggressiveClassifier(C=1.0, average=False,\n",
       "                                             class_weight=None,\n",
       "                                             early_stopping=False,\n",
       "                                             fit_intercept=True, loss='hinge',\n",
       "                                             max_iter=1000, n_iter_no_change=5,\n",
       "                                             n_jobs=None, random_state=0,\n",
       "                                             shuffle=True, tol=0.001,\n",
       "                                             validation_fraction=0.1, verbose=0,\n",
       "                                             warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM -Feature Selection and Training\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pa_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), \n",
    "                    ('clf', PassiveAggressiveClassifier(max_iter=1000, random_state=0, tol=1e-3)),])\n",
    "\n",
    "pa_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3jR-UtLbGSy4"
   },
   "outputs": [],
   "source": [
    "#Prediction using Passive Aggressive Classifier\n",
    "y_pred_pac = pa_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "No_fq9biciv2",
    "outputId": "413b8a3b-96bd-46ab-acf7-2bfb168fa8e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.11      0.05      0.07        43\n",
      "        ENFP       0.28      0.30      0.29       139\n",
      "        ENTJ       0.20      0.11      0.15        35\n",
      "        ENTP       0.32      0.23      0.27       138\n",
      "        ESFJ       0.00      0.00      0.00        13\n",
      "        ESFP       0.00      0.00      0.00         8\n",
      "        ESTJ       0.00      0.00      0.00         8\n",
      "        ESTP       0.00      0.00      0.00        16\n",
      "        INFJ       0.39      0.44      0.42       295\n",
      "        INFP       0.44      0.55      0.49       356\n",
      "        INTJ       0.37      0.36      0.36       239\n",
      "        INTP       0.43      0.49      0.46       277\n",
      "        ISFJ       0.44      0.20      0.27        35\n",
      "        ISFP       0.24      0.09      0.12        47\n",
      "        ISTJ       0.32      0.29      0.30        24\n",
      "        ISTP       0.36      0.27      0.31        62\n",
      "\n",
      "    accuracy                           0.38      1735\n",
      "   macro avg       0.24      0.21      0.22      1735\n",
      "weighted avg       0.36      0.38      0.37      1735\n",
      "\n",
      "Confusion Metrix: \n",
      " [[  2   3   0   3   0   0   0   0  16  11   3   1   1   1   1   1]\n",
      " [  5  42   1   7   0   0   0   1  24  39   6  13   0   0   0   1]\n",
      " [  1   3   4   4   0   0   0   0   3   3  10   4   1   0   0   2]\n",
      " [  1  11   3  32   0   0   0   0  11  16  14  39   0   2   2   7]\n",
      " [  0   2   0   0   0   0   0   1   6   3   0   0   0   0   0   1]\n",
      " [  0   1   0   2   0   0   1   0   2   0   0   2   0   0   0   0]\n",
      " [  0   1   0   1   0   0   0   0   0   3   2   0   0   1   0   0]\n",
      " [  0   2   0   1   0   0   0   0   1   4   3   2   0   0   0   3]\n",
      " [  4  18   3   6   0   0   0   2 131  81  27  14   0   3   3   3]\n",
      " [  1  25   3   5   0   0   1   0  57 197  24  34   4   3   0   2]\n",
      " [  1  13   3  17   0   0   0   1  33  31  87  45   0   1   1   6]\n",
      " [  1  17   1  14   1   0   0   0  25  39  40 135   0   0   2   2]\n",
      " [  1   5   1   0   1   0   0   1   4   5   1   3   7   1   4   1]\n",
      " [  1   4   1   1   0   0   0   0  14  10   5   5   1   4   1   0]\n",
      " [  0   1   0   2   0   0   0   0   1   2   9   1   0   0   7   1]\n",
      " [  0   2   0   6   0   1   0   0   4   8   7  13   2   1   1  17]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix and Accuracy Score of Naive Bayes\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_pred_pac, zero_division=1))\n",
    "\n",
    "print(\"Confusion Metrix: \\n\", confusion_matrix(y_test, y_pred_pac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7K9NH5K7Hphm",
    "outputId": "ff983fa0-3530-41c2-807b-c681bb9e9497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (0.17.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/content/drive/My Drive/Data_Science/personify_pac_model.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the SVM machine learning model to a file\n",
    "!pip install joblib\n",
    "import joblib\n",
    "joblib.dump(pa_clf, \"/content/drive/My Drive/Data_Science/personify_pac_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qimWvsKYRK86"
   },
   "source": [
    "## Trying out Neural Nets for better performance on data set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFpOL8m9ejwH"
   },
   "source": [
    "\n",
    "## Deep Learning Models\n",
    "    Training Model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRJXhHrxpGxM"
   },
   "source": [
    "### 1. Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7lL5iLjnJ3d1",
    "outputId": "c683cdb2-0090-4c28-fd64-fe0710cee361"
   },
   "outputs": [],
   "source": [
    "# # Tokenize the data into a format that can be used by the word embeddings\n",
    "# from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# tokenizer = Tokenizer(num_words=5000, lower=False)\n",
    "# tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# print(X_train[2])\n",
    "# X_train = tokenizer.texts_to_sequences(X_train)\n",
    "# X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# # vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "\n",
    "# # tokenizer.fit_on_texts(y_train)\n",
    "# # y_train = tokenizer.texts_to_sequences(y_train)\n",
    "# # y_test = tokenizer.texts_to_sequences(y_test)\n",
    "\n",
    "# print(X_train[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvn1HbEd-b_x"
   },
   "source": [
    "### Word Vector Padding\n",
    "    CountVectorizer produces word vectors with diferent lengths.\n",
    "    pad_sequence(), simply pads the sequence of words with zeros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MDA2Le-c-9Rg",
    "outputId": "9270b3d4-7e3a-4884-9db6-3f85017feebe"
   },
   "outputs": [],
   "source": [
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "# maxlen = 100\n",
    "\n",
    "# X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "# X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "# # y_train = pad_sequences(y_train, padding='post', maxlen=maxlen)\n",
    "# # y_test = pad_sequences(y_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "\n",
    "# print(X_train[0, :])\n",
    "# # print(X_train_tfidf)\n",
    "# # print(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V7Xau_9zlBPA",
    "outputId": "5fe96d33-ff5f-4696-c0a0-5833d22c5c1b"
   },
   "outputs": [],
   "source": [
    "# # import tensorflow as tf\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import Flatten\n",
    "# from keras.layers.convolutional import Conv1D\n",
    "# from keras.layers import GlobalMaxPool1D\n",
    "# from keras.layers.embeddings import Embedding\n",
    "# from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "# input_dim = X_train.shape[0]  # Number of features\n",
    "# embedding_dim = 50\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(input_dim=input_dim, \n",
    "#                            output_dim=embedding_dim, \n",
    "#                            input_length=maxlen,))\n",
    "# model.add(GlobalMaxPool1D())\n",
    "# # model.add(Flatten())\n",
    "# #Adding two Dense layers in the sequential nn model\n",
    "# model.add(Dense(10, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# #Uses tensorflow in the backend.\n",
    "# X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g5s1imd-40L8",
    "outputId": "57cc7dc9-aac4-47ec-f666-00b37a77d8d4"
   },
   "outputs": [],
   "source": [
    "#Giving model a loss function, optimizer and a metrics for evaluation\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRtqA3Vg6T7A"
   },
   "source": [
    "### Epochs and Training NN\n",
    "    Training in neural networks is an iterative process, the training won’t just stop after it is done. You have to specify the number of iterations you want the model to be training. Those completed iterations are commonly called epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "48qVBnB26rNb",
    "outputId": "c1cd8d48-daa2-4f8a-df15-36d8e196b1cd"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# X_train = np.asarray(X_train)\n",
    "# y_train = np.asarray(y_train)\n",
    "# X_test = np.asarray(X_test)\n",
    "# y_test = np.asarray(y_test)\n",
    "\n",
    "# history = model.fit(X_train, y_train, epochs=5, verbose=False, validation_data=(X_test, y_test), batch_size=10)\n",
    "\n",
    "# loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "# print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "# loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "# print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDQOrYT_9TFj"
   },
   "source": [
    "# Parameter tuning using grid search\n",
    "    Hyper Parameter Tuning"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "VxnAiQ3fl-EC",
    "JFpOL8m9ejwH",
    "TRJXhHrxpGxM",
    "pvn1HbEd-b_x",
    "aRtqA3Vg6T7A"
   ],
   "name": "Personify.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
